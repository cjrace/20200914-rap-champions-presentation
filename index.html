<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>Where RAP meets analysts</title>
    <meta charset="utf-8" />
    <meta name="author" content="Cam Race" />
    <link rel="stylesheet" href="xaringan-themer.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

# Where RAP meets analysts
## Stats production in DfE
### Cam Race
### 2020/09/14

---






# What I'll cover

???

Want to update others on what we're doing

highlight things we've come across incase any of it is useful to others

to invite feedback/questions on what we've done and plan to do



--

Our plan for implementing RAP across stats production in DfE
- setting the scope and details

--

Work so far
- documentation
- dissemination platform
- open data standards

--

Focused example
- automated screening of data files against standards that we have for open data files

--

Next steps and reflections

---

# Who are we

Statistics Development Team - Data Insight and Statistics Division - DfE

Central team who:

- are overseeing the development of a new dissemination platform

- offer support to teams for all kinds of things related to the production of 60 publications

- set and encourage best practices in production processes


Team is made up of myself and Laura Selby

???

Example of currently working with a team to automate their secondary suppression processes

---
layout: true

# What is RAP

---

--

Don't worry, I'm not going to explain to the RAP champions what RAP is

This was useful in creating a plan for how to implement and encourage RAP across the analysts

???

We couldn't start being effective until we knew exactly what RAP looked like for us

--

Using this question, we defined the broad scope of it

.center[![Arrows defining the scope of DfE RAP plan](examples/RAP-Scope-Arrow.png)]

???

This arrow shows the areas that all publication teams may have involvement in

Teams vary on the amount of this they cover, some are heavily involved in the collection, and others don't have any involvement until after it's been cleaned

We then decided to focus our efforts into the place where we have full control, and where we'll get the biggest benefits for all teams

and while we can apply RAP to Publication writing, we felt that this would bring less benefits than in production processes themselves

---

We then continued to define what RAP was to us by creating a detailed pipeline of the scope from the previous slide

.center[![Overview of DfE RAP plan](examples/RAP-Process-Overview.png)]

???

Can flick back to the previous side to highlight how the ends of this diagram are the ends of the scope on the arrow before. 

It's less important the detail and more that we were defining it so clearly and breaking it into easily target-able objects

---

We also took that a step further with the following diagram for breaking down what using RAP for that scope means in practice for teams

.center[![Hexagons breaking down RAP to real world examples](examples/RAP-in-practice.png)]

???

Highlight a couple of the hexagons, and then how this was all designed around making it easier to understand for the analysts

Also flag that the Good used to be called minimum, though we needed to be a bit more positive/encouraging to teams

Makes it feel easier to pick up a single thing for a team, rather than feeling like the whole of that block is unachievable

Successful implementation has relied on the human users of RAP

---
layout: false

# Explore Education Statistics

A big part of this has been utilising the new dissemination platform as a catalyst

Provided an ideal opportunity to overhaul and review all aspects of our work

Our data files had to be standardised to run the platform off of the aggregated data, giving us a consistent end point to the pipeline I showed earlier

--

Brief demo of [Explore Education Statistics](https://explore-education-statistics.service.gov.uk/) to give context

---

# Guidance

A key part of RAP is documentation, and implementing RAP has been no different

We found that we had an ever increasing amount of documents laying around

Issues with finding things quickly, making sure it was the latest version, and for everyone else to do so too

--

So we made an [rmarkdown website](https://rsconnect/rsc/stats-production-guidance/) where all of our guidance is stored in a single, maintained place

???

Demo - a lot to cover so try to go quickly

L+D - tools that we recommend as we can support them easily and resources to learn them

RAP - principles of RAP and checklist

Data standards and everything a quick whizz

--

Note that this is not publicly accessible, it is limited to DfE only as it runs off of our rsconnect servers

---
layout: true

# Data standards

---

Built around principles of tidy data

Essentially:

- Every row refers to a single observational unit
- Every column refers to a single variable 
  - 'filters' for categorical variables
  - 'indicators' for the numeric measures that we report
- Specific standards around time and geography so the that platform can handle them

---

Benefits of these standards:

- Machine readable

- 3* open data standards

- Consistent across totally different areas for end users

- Consistency of end target makes it easier to write code that can be generalised across all of our files

---

Show two example files

These are included in the repo for reference

---

Now we have standards, how can we check against them?

--

I started off for a couple of months manually checking for:

- Mandatory columns
- Correct labelling
- Appropriate structure
- Spaces in variable names

--

and this list kept growing...

--

and the number of files kept growing...

---
layout: false

# Automated screening

Easy to see the motivations for automating the screening of files

- Save time

- Improve accuracy

- Increase reliability

- Remove single-person dependency

- Empower analysts to do this themselves (this comes later)


???
Across the 60 publications we have at least 500 open data files

It was unrealistic for anyone to check these manually

Design and usage - I'm going to talk through some of the iterations we've had

and how/why it's evolved based on feedback

---

# First iteration

[Single script](https://github.com/dfe-analytical-services/ees-data-screener/blob/8d4ebdbe8507741cc58e19ac6ff8566939b9ea0d/checking_script.R) that I could use myself to automate the checking part of what I was doing

- Basic checks in an Rscript I had locally

- Output in console

- Run by myself, and manually fed back to teams

- Basic coverage, though fast, accurate, and reliable for the tests present

???

A number of things to improve, though one specific thing I'll highlight is how the tests could fail early, which goes against the best practice in automated testing where you want maximum coverage, so that you can get as much useful information as possible, and minimise the need to rerun - I'll come back to this later

---

# Second iteration

Created an [Rmarkdown report](examples/iteration1_report.html) to send to analysts - [GitHub repo](https://github.com/dfe-analytical-services/ees-data-screener/tree/70c37e6d83b2a6c83141949daf55d2ffed95e62b)

- Version controlled using git keeping the development process clear

- In a public github repo to make it accessible

- Saved me time manually checking through results in the console

- Gave an audit trail of the screening for future reference

??? 

Helped to remove some more of the human error from the process, automating the reporting as well as the checking

---

# Third iteration

Similar structure, with more tests, summary stats and nicer report

Also more options for selecting files, including a console only option without a report for larger files

- Making it easier for analysts to see when there were issues flagged

- First time starting to think about the length of time the code takes to run as file sizes increased

- Made it easier for analysts to run this project themselves by using renv for package management


Give demonstration of using the tool - [GitHub repo](https://github.com/dfe-analytical-services/ees-data-screener)

---
layout: true

# Setup video

---

I found that I was spending hours of my time going through with analysts setting this up, repeating the same things over and over

So rather than constantly doing the verbal equivalent of churning out the same code over and over, I recorded a 10 minute youtube video instead

---

Walked through everything, including:
- The basics of getting the correct R and RStudio versions from the DfE software centre
- How to download/clone from GitHub
- How to unzip a compressed file
- How to open an R Project and run a script
- Then how to use the specific project I'd made

---

Saved myself sitting beside each of the analysts at their desks to do this


Proved very popular, empowering analysts


Effective in reducing repetitive queries to me

???

I'm also fairly sure that this alone dramatically increased the number of publication teams who had a version of R/RStudio on their machines in our department

---
layout: false

# renv

As great as renv is, there were still issues with it, it wasn't working for every person who wanted to run it

I ended up scrapping it in favour of [a temporary solution](https://github.com/dfe-analytical-services/ees-data-screener) to tide me over until the next iteration came along


- .Rprofile script automatically sets the library to match working directory of the project

- library folder with the packages needed in it saved in the project directory

???

Go to repo and show rprofile and library scripts

Not a sustainable solution, and renv is far better, though this was a short term thing that worked, and worked more reliably than renv was doing at the time

---
layout: true

# Current iteration 

---

Converted the code to make an [R Shiny app](https://rsconnect/rsc/dfe-published-data-qa/)

- Back to renv

- Removes R and Rstudio barrier

- Reduces dependency issues to server only, rather than 100+ different laptops

- Single version of the truth, no need to redownload/pull latest version

- Increased speed by refactoring code

- Increased test coverage 

- Automated tests using testthat and shinytest that run locally to automate the testing of any new code that goes into the app

???

using profvis to profile code, highlight slowest parts and refactored accordingly

130mb file, previously had 36 tests, taking over 4 minutes

Now have 60 tests and running in around 13 seconds

now 60 checks and counting, with preliminary stages to allow for maximum coverage while minimising confusing cross-errors where possible

---

Feedback has been fantastic, overwhelmingly positive, easy to use, far quicker and more efficient

For me personally, I never have to manually check another file again unless it an edge case

Even then, I've not found an edge case that will break the app, it will handle any files thrown at it gracefully

---
layout: false

# Particularly useful things

Testing for duplicate rows

- almost scary how many analysts started to notice things in their data after I added this test, seems to be an easy SQL slip

- `janitor::get_dupes()` 

---
layout: true

# Particularly useful things

---

White space, it can lead to many issues, and can be impossible to spot manually

- Using `fread(data, strip.white = FALSE)` and testing for spaces

```
data_variable_spaces &lt;- function(data) {
  data_spaces_check &lt;- function(i) {
    if (any(grepl("\\s", i))) {
      return("FAIL")
    } else {
      return("PASS")
    }
  }

  pre_result &lt;- stack(sapply(names(data), data_spaces_check))

  if (all(pre_result$values == "PASS")) {
    output &lt;- list(
      "message" = "There are no spaces in the variable names.",
      "result" = "PASS"
    )
  } else {
```
etc...

---

profvis - package to easily profile R code, recording how long different parts are taking to run

- helped to spot unnecessary uses of `grepl()`, where `vector_of_values %in% dataset$column` would suffice

- along with finding `use.names = FALSE` for `unlist()` leading to incredible time savings

---

testthat and shinytest for automated unit and UI testing of the code

- both very easy to use and quick to set up

```
run_tests &lt;- function() {
  Sys.unsetenv("http_proxy")
  Sys.unsetenv("https_proxy")
  source("global.r")
  message("================================")
  message("== testthat ====================")
  message("")
  testthat::test_dir("tests/testthat")
  message("")
  message("================================")
  message("== shinytest ===================")
  message("")
  shinytest::testApp()
  message("")
  message("================================")
}
```

---

styler for automating the formatting of code to tidyverse standards 

- though make sure you're version controlling to check what it does change, I've not had any issues yet but better to be safe

```
tidy_code &lt;- function() {
  install.packages("styler")
  library(styler)
  styler::style_dir(recursive = FALSE)
  styler::style_dir("R/")
  styler::style_dir("tests/shinytest/", recursive = FALSE)
  styler::style_dir("tests/testthat/", recursive = FALSE)
}
```

---

- Commenting in a way to make use of the outline as scripts get longer - Ctrl-Shft-O in RStudio

---
layout: true

# Next steps

---

### This week

Integrate automated tests into DevOps deployment pipeline - have struggled so far, though looking at options

---

### This month

Automated QA / sense checking adding to app if a file passes 
- again trying to lower the barrier to the benefits of automating common tasks

---

### Generally

Continue to build on documentation, and features/code to help analysts make the most of RAP

---
layout: false

# Recap

--

Gave on overview of how we've approached implementing RAP


A specific example of allowing analysts to take advantage of elements of RAP while lowering the barriers of technical knowledge


There is a surprisingly widespread fear of code and RAP/R anything that goes with it


Different methods such as tutorial videos


Giving guidance on the basics, what to learn, how to learn


Even how to download and get the software running on their machine

---

class: center, middle

# Thanks!

Slides available at [...]()

Made with [xarigan](https://bookdown.org/yihui/rmarkdown/xaringan.html) rmarkdown extension

Any questions?

Contact: [cameron.race@education.gov.uk](mailto:cameron.race@education.gov.uk)

???

Thank you all for listening

Slides are available at that link there

This was made with xarigan package, which is an extension for rmarkdown, and I'd really recommend you check it out, the amount of flexibility is incredible and the keyboard shortcuts are really nice when presenting

I think there's a few minutes now if anyone has any questions, though there's also my email there if you have questions or suggestions afterwards
    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create();
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
