---
title: "Where RAP meets analysts"
subtitle: "Our journey in DfE"
author: "Cam Race"
date: "2020/09/08 (updated: `r format(Sys.Date(), '%Y/%m/%d')`)"
output:
  xaringan::moon_reader:
        css: "xaringan-themer.css"
---

```{r xaringan-themer, include=FALSE}
library(xaringanthemer)
style_duo(
  primary_color = "#1F4257", 
  secondary_color = "#F97B64",
  header_font_google = google_font("Poppins", "400"),
  text_font_google   = google_font("Poppins", "250", "250i"),
  code_font_google   = google_font("IBM Plex Mono")
  )
```

```{r setup, include=FALSE}
library(knitr)
library(showtext)
library(xaringan)
library(rmarkdown)
knitr::opts_chunk$set(echo = FALSE)
knitr::opts_chunk$set(error = FALSE)
```

# Introduction

- Our plan for RAP
- Work so far
- Focus in on the automated screening checks, which came after setting our tidy data
- End with automating QA more widely (next point of focus of the overall plan)

---

# What is RAP

Don't worry, I'm not going to preach the choir here.

However, this is always the most important question to start with - we couldn't start being effective until we knew what RAP looked like for us. 

In order to do that, we clearly defined the scope of it...

RAP DIAGRAM

---

# Work so far

?

---

# Explore Education Statistics

This was all done by utilising the new dissemination platform as a catalyst

Change was already coming, therefore it was an ideal time to jump on the back of it to make that change a positive one

Brief demo of [Explore Education Statistics](https://explore-education-statistics.service.gov.uk/)

---

# Guidance

A key part of RAP is documentation, and implementing RAP has been no different.

We have an [rmarkdown website](https://rsconnect/rsc/stats-production-guidance/) where all of our guidance is stored.

Note that this is not publicly accessible, it is limited to DfE only as it runs off of our rsconnect servers.

---

# Data standards

Built around principles of tidy data

Examples (pick two very different subject areas)

Still have debates now, where is the line between levels of categorical variable and a separate measurable variable, balance between 'molten' and 'tidy'.

Ultimately, we've aimed to give analysts as much flexibility as we can within the constraints.

---

# Now we have standards, how can we check against them?

Motivation for tool
- Save time
- Accuracy
- Reliability
- Remove single-person dependency
- Empower analysts to do this themselves

Design and usage 

How it's evolved based on feedback

The feedback I've had

---

# Notes to fit in

Make sure to play on the user side, and how we've taken approaches that allow analysts to take advantage of RAP without needing to be overly technical, this has been the biggest challenge in implementation. Almost don't want them to care about 'RAP' in name, and instead the practical side of what we need to do in the day to day to improve our processes (and bring the many bounteous benefits of RAP that all of us are aware of)


---

# First iteration

Basic checks in an Rscript

Output in console

Run by myself, and manually fed back to teams

A number of things to improve, though one I'll highlight is how the tests could fail early, which goes against the best practice in automated testing where you want maximum coverage, so that you can get as much useful information as possible, and minimise the need to rerun - I'll come back to this later

---

# Second iteration

Rmarkdown

# Third iteration

Summary stats, and console only option for larger files

---

# Current iteration 

Shiny app

Automated tests using testthat and shinytest that run locally to automate the testing of any new code that goes into the app

---

# Next steps

Integrate automated tests into devops - have struggled so far?

Automated QA in app (alongside guidance and code examples)

Continue to build on documentation, and features/code to help analysts make the most of RAP

Further work to push this with our HoP, and get pressure the top to make more analysts make time for this

Go back to the plan and target other areas

---

# Recap

In some ways, you could say it's been quite simple:
- Defined what 'RAP' was to us
- Targetted specific areas of that plan
- Iterated the solutions based on feedback
- All the while learning more and more about R and what can be done with it
- Keep pushing to improve moving forwards

3 biggest challenges

1. Understanding why things are the way they are
2. Working out how to effectively implement RAP using knowledge of 1.
3. Having a limited resource pool and indifferent senior managers

Ultimately all have been overcome by a lot of effort, though it's not always simple or easy...

---

class: center, middle

# Thanks!

Any questions?

Contact [cameron.race@education.gov.uk](mailto:cameron.race@education.gov.uk).
